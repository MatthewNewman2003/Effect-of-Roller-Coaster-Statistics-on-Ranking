{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "5FBhY6VogwJD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtA3Y2rhf8YC"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading Data**"
      ],
      "metadata": {
        "id": "33S26W1Lg0rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring missing denoter\n",
        "MissingValues = [\"N/A\"]\n",
        "\n",
        "#Declaring Google Drive URL\n",
        "GoogleDriveURL = \"https://docs.google.com/spreadsheets/d/1OfxlATMBJJwN1VjW7sb0jKwIFywJcACbZYJHIxbjdVc/export?format=csv&gid=0\"\n",
        "\n",
        "#Reading the CSV file into a Pandas DataFrame\n",
        "DataFrame = pd.read_csv(GoogleDriveURL, na_values=MissingValues)"
      ],
      "metadata": {
        "id": "HPcrPvtNg3Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the DataFrame head\n",
        "DataFrame.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n-lzC44Rh4BR",
        "outputId": "e5625627-3304-4189-ce91-e8fd76b6370f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Ranking             Name                  Park  Height  Speed  Length  \\\n",
              "0        1  Steel Vengeance           Cedar Point   205.0   74.0  5740.0   \n",
              "1        2       Iron Gwazi   Busch Gardens Tampa   206.0   76.0  4075.0   \n",
              "2        3            Zadra          Energylandia   206.0   75.2  4317.6   \n",
              "3        4    VelociCoaster  Islands of Adventure   155.0   70.0  4700.0   \n",
              "4        5        Eejanaika       Fuji-Q Highland   249.3   78.3  3782.8   \n",
              "\n",
              "   Inversions  Opening Year  \n",
              "0           4        2018.0  \n",
              "1           2        2022.0  \n",
              "2           3        2019.0  \n",
              "3           4        2021.0  \n",
              "4           3        2006.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f07a7d26-cf81-40aa-a4d1-6b95cc1e7a5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Name</th>\n",
              "      <th>Park</th>\n",
              "      <th>Height</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Length</th>\n",
              "      <th>Inversions</th>\n",
              "      <th>Opening Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Steel Vengeance</td>\n",
              "      <td>Cedar Point</td>\n",
              "      <td>205.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>5740.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2018.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Iron Gwazi</td>\n",
              "      <td>Busch Gardens Tampa</td>\n",
              "      <td>206.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4075.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2022.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Zadra</td>\n",
              "      <td>Energylandia</td>\n",
              "      <td>206.0</td>\n",
              "      <td>75.2</td>\n",
              "      <td>4317.6</td>\n",
              "      <td>3</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>VelociCoaster</td>\n",
              "      <td>Islands of Adventure</td>\n",
              "      <td>155.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4700.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2021.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Eejanaika</td>\n",
              "      <td>Fuji-Q Highland</td>\n",
              "      <td>249.3</td>\n",
              "      <td>78.3</td>\n",
              "      <td>3782.8</td>\n",
              "      <td>3</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f07a7d26-cf81-40aa-a4d1-6b95cc1e7a5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f07a7d26-cf81-40aa-a4d1-6b95cc1e7a5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f07a7d26-cf81-40aa-a4d1-6b95cc1e7a5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25c1b4c2-bade-44d0-b46e-4adaf361d912\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25c1b4c2-bade-44d0-b46e-4adaf361d912')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25c1b4c2-bade-44d0-b46e-4adaf361d912 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DataFrame",
              "summary": "{\n  \"name\": \"DataFrame\",\n  \"rows\": 1863,\n  \"fields\": [\n    {\n      \"column\": \"Ranking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 569,\n        \"min\": 1,\n        \"max\": 1978,\n        \"num_unique_values\": 1863,\n        \"samples\": [\n          236,\n          539,\n          1267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1484,\n        \"samples\": [\n          \"Thunderbird\",\n          \"Montezooma's Revenge\",\n          \"Momonga\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Park\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 567,\n        \"samples\": [\n          \"Chuanlord Holiday Manor\",\n          \"Magic Park Land\",\n          \"Camelot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53.85904813013668,\n        \"min\": 9.5,\n        \"max\": 456.0,\n        \"num_unique_values\": 367,\n        \"samples\": [\n          78.8,\n          236.0,\n          106.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.26518744511551,\n        \"min\": 8.0,\n        \"max\": 149.1,\n        \"num_unique_values\": 214,\n        \"samples\": [\n          95.0,\n          39.1,\n          55.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1391.06782629188,\n        \"min\": 190.0,\n        \"max\": 17388.5,\n        \"num_unique_values\": 763,\n        \"samples\": [\n          1365.0,\n          1850.4,\n          450.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inversions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          7,\n          4,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Opening Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.036591179255538,\n        \"min\": 1902.0,\n        \"max\": 2025.0,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          1936.0,\n          1991.0,\n          1928.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking the Data**"
      ],
      "metadata": {
        "id": "oOg25MvriDGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the head of the data without the name and park columns\n",
        "DataFrame = DataFrame.drop(columns=[\"Name\", \"Park\"])\n",
        "DataFrame.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6Z_zd7YCiPj2",
        "outputId": "ee8fb29e-645c-4090-ff14-9a6b256582b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Ranking  Height  Speed  Length  Inversions  Opening Year\n",
              "0        1   205.0   74.0  5740.0           4        2018.0\n",
              "1        2   206.0   76.0  4075.0           2        2022.0\n",
              "2        3   206.0   75.2  4317.6           3        2019.0\n",
              "3        4   155.0   70.0  4700.0           4        2021.0\n",
              "4        5   249.3   78.3  3782.8           3        2006.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ecaa9c8-7e0f-45e1-9ad1-e7344037c71e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Height</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Length</th>\n",
              "      <th>Inversions</th>\n",
              "      <th>Opening Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>205.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>5740.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2018.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>206.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4075.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2022.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>206.0</td>\n",
              "      <td>75.2</td>\n",
              "      <td>4317.6</td>\n",
              "      <td>3</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>155.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4700.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2021.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>249.3</td>\n",
              "      <td>78.3</td>\n",
              "      <td>3782.8</td>\n",
              "      <td>3</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ecaa9c8-7e0f-45e1-9ad1-e7344037c71e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ecaa9c8-7e0f-45e1-9ad1-e7344037c71e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ecaa9c8-7e0f-45e1-9ad1-e7344037c71e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-90560ea3-8be5-47ad-965a-6b9294613822\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90560ea3-8be5-47ad-965a-6b9294613822')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-90560ea3-8be5-47ad-965a-6b9294613822 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DataFrame",
              "summary": "{\n  \"name\": \"DataFrame\",\n  \"rows\": 1863,\n  \"fields\": [\n    {\n      \"column\": \"Ranking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 569,\n        \"min\": 1,\n        \"max\": 1978,\n        \"num_unique_values\": 1863,\n        \"samples\": [\n          236,\n          539,\n          1267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53.85904813013668,\n        \"min\": 9.5,\n        \"max\": 456.0,\n        \"num_unique_values\": 367,\n        \"samples\": [\n          78.8,\n          236.0,\n          106.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.26518744511551,\n        \"min\": 8.0,\n        \"max\": 149.1,\n        \"num_unique_values\": 214,\n        \"samples\": [\n          95.0,\n          39.1,\n          55.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1391.06782629188,\n        \"min\": 190.0,\n        \"max\": 17388.5,\n        \"num_unique_values\": 763,\n        \"samples\": [\n          1365.0,\n          1850.4,\n          450.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inversions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          7,\n          4,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Opening Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.036591179255538,\n        \"min\": 1902.0,\n        \"max\": 2025.0,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          1936.0,\n          1991.0,\n          1928.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seeing how many missing values there are per column\n",
        "missing_values_per_column = DataFrame.isna().sum()\n",
        "print(missing_values_per_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0-OwIcvitA9",
        "outputId": "45a72a13-d710-4a67-a2ff-4b6b97133189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking           0\n",
            "Height          476\n",
            "Speed           532\n",
            "Length          302\n",
            "Inversions        0\n",
            "Opening Year     26\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropping Records with NA Values**"
      ],
      "metadata": {
        "id": "3OunBWau9qmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping records with NA values and adjusting the DataFrame\n",
        "DataFrame = DataFrame.dropna()\n",
        "DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "r_21CqfF9u8f",
        "outputId": "51691997-2358-4c08-f898-2c07d4e9bf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Ranking  Height  Speed  Length  Inversions  Opening Year\n",
              "0           1   205.0   74.0  5740.0           4        2018.0\n",
              "1           2   206.0   76.0  4075.0           2        2022.0\n",
              "2           3   206.0   75.2  4317.6           3        2019.0\n",
              "3           4   155.0   70.0  4700.0           4        2021.0\n",
              "4           5   249.3   78.3  3782.8           3        2006.0\n",
              "...       ...     ...    ...     ...         ...           ...\n",
              "1852     1967   101.7   49.7  2171.9           5        1994.0\n",
              "1855     1970    39.4   31.3   557.7           0        2023.0\n",
              "1859     1975    50.0   25.7  1282.8           2        2004.0\n",
              "1860     1976    36.1   26.7  1017.1           0        2014.0\n",
              "1862     1978    27.9   26.8   423.2           0        2024.0\n",
              "\n",
              "[1203 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d76a5b5-585f-4bac-bf4e-685568ad42b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ranking</th>\n",
              "      <th>Height</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Length</th>\n",
              "      <th>Inversions</th>\n",
              "      <th>Opening Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>205.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>5740.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2018.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>206.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4075.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2022.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>206.0</td>\n",
              "      <td>75.2</td>\n",
              "      <td>4317.6</td>\n",
              "      <td>3</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>155.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4700.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2021.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>249.3</td>\n",
              "      <td>78.3</td>\n",
              "      <td>3782.8</td>\n",
              "      <td>3</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1852</th>\n",
              "      <td>1967</td>\n",
              "      <td>101.7</td>\n",
              "      <td>49.7</td>\n",
              "      <td>2171.9</td>\n",
              "      <td>5</td>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1855</th>\n",
              "      <td>1970</td>\n",
              "      <td>39.4</td>\n",
              "      <td>31.3</td>\n",
              "      <td>557.7</td>\n",
              "      <td>0</td>\n",
              "      <td>2023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1859</th>\n",
              "      <td>1975</td>\n",
              "      <td>50.0</td>\n",
              "      <td>25.7</td>\n",
              "      <td>1282.8</td>\n",
              "      <td>2</td>\n",
              "      <td>2004.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1860</th>\n",
              "      <td>1976</td>\n",
              "      <td>36.1</td>\n",
              "      <td>26.7</td>\n",
              "      <td>1017.1</td>\n",
              "      <td>0</td>\n",
              "      <td>2014.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1862</th>\n",
              "      <td>1978</td>\n",
              "      <td>27.9</td>\n",
              "      <td>26.8</td>\n",
              "      <td>423.2</td>\n",
              "      <td>0</td>\n",
              "      <td>2024.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1203 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d76a5b5-585f-4bac-bf4e-685568ad42b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d76a5b5-585f-4bac-bf4e-685568ad42b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d76a5b5-585f-4bac-bf4e-685568ad42b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4a131bd-3f9c-43da-bb8a-a8b8bcfd7f18\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4a131bd-3f9c-43da-bb8a-a8b8bcfd7f18')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4a131bd-3f9c-43da-bb8a-a8b8bcfd7f18 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_69edc5ba-dee2-4748-b294-4c9f3164806c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('DataFrame')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_69edc5ba-dee2-4748-b294-4c9f3164806c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('DataFrame');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DataFrame",
              "summary": "{\n  \"name\": \"DataFrame\",\n  \"rows\": 1203,\n  \"fields\": [\n    {\n      \"column\": \"Ranking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 569,\n        \"min\": 1,\n        \"max\": 1978,\n        \"num_unique_values\": 1203,\n        \"samples\": [\n          1806,\n          500,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54.86943682471652,\n        \"min\": 10.8,\n        \"max\": 456.0,\n        \"num_unique_values\": 348,\n        \"samples\": [\n          60.0,\n          102.3,\n          173.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.25563996146324,\n        \"min\": 11.2,\n        \"max\": 149.1,\n        \"num_unique_values\": 204,\n        \"samples\": [\n          64.6,\n          95.0,\n          42.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1264.3176779647736,\n        \"min\": 197.5,\n        \"max\": 8133.2,\n        \"num_unique_values\": 628,\n        \"samples\": [\n          2746.0,\n          3116.8,\n          1320.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inversions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Opening Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.684086384450225,\n        \"min\": 1914.0,\n        \"max\": 2025.0,\n        \"num_unique_values\": 81,\n        \"samples\": [\n          2005.0,\n          2018.0,\n          1994.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examining the New Correlations after the Removal of Records with NA Values**"
      ],
      "metadata": {
        "id": "PzIXgLLh95MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the correlations between the statistics and ranking\n",
        "Correlations = DataFrame.corr(numeric_only=True)\n",
        "CorrelationWithRanking = Correlations[[\"Ranking\"]].drop(index=\"Ranking\").sort_values(by=\"Ranking\", ascending=False)"
      ],
      "metadata": {
        "id": "4uFlHcJN_bbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the correlations in a correlation matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(CorrelationWithRanking, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title(f'New Correlation of Predictors with Ranking')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "nbwkuFQ9AMMm",
        "outputId": "7a73f272-f2c7-4f53-8d98-3e3e7b63aa70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing/Train-Test Split for All Predictive Features**"
      ],
      "metadata": {
        "id": "9z0pAYgQRScb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into X and Y columns, with X denoting the predictors and Y denoting the target\n",
        "X = DataFrame.drop(columns=[\"Ranking\"])\n",
        "Y = DataFrame[\"Ranking\"]\n",
        "#Performing a train/test split to provide a holdout test set to evaluate on\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=254)"
      ],
      "metadata": {
        "id": "KAEq4Ds8jKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling the predictive features to ensure that differences in quantity are not unduly influencing the models\n",
        "FeatureScaler = MinMaxScaler()\n",
        "X_train_Scaled = FeatureScaler.fit_transform(X_train)\n",
        "X_test_Scaled = FeatureScaler.transform(X_test)\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHDYQfbgj067",
        "outputId": "a6fd1c9e-bd0f-4d35-a5eb-13bf1bd316cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Height  Speed  Length  Inversions  Opening Year\n",
            "1676    27.9   21.7   679.2           0        1999.0\n",
            "89     131.0   58.0  3300.0           3        2022.0\n",
            "521     55.0   50.0  2650.0           0        1935.0\n",
            "355     80.0   48.0  2800.0           0        1995.0\n",
            "1680    27.9   21.7   679.1           0        1998.0\n",
            "...      ...    ...     ...         ...           ...\n",
            "1455    85.0   48.0  2050.0           3        1976.0\n",
            "1516    64.0   37.3  1148.3           2        1982.0\n",
            "699    180.0   37.3  2368.0           0        2007.0\n",
            "116    126.3   62.1  4317.6           4        2021.0\n",
            "1137    75.5   37.3   672.6           0        2024.0\n",
            "\n",
            "[962 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression (All Features)**"
      ],
      "metadata": {
        "id": "1PDge0gFTcAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decalring a linear regression model and fitting it on the training set\n",
        "LinRegAll = LinearRegression()\n",
        "LinRegAll.fit(X_train_Scaled, Y_train)\n",
        "\n",
        "#Making predictions with it on the test set\n",
        "Predictions = LinRegAll.predict(X_test_Scaled)\n",
        "\n",
        "#Calculating the mean ranking in the test set\n",
        "Y_mean = np.mean(Y_test)\n",
        "\n",
        "#Calculating various metrics of success for the model\n",
        "RSquared = LinRegAll.score(X_test_Scaled, Y_test)\n",
        "MeanAbsoluteError = mean_absolute_error(Y_test, Predictions)\n",
        "MeanSquaredError = mean_squared_error(Y_test, Predictions)\n",
        "RMSE = np.sqrt(MeanSquaredError)\n",
        "ScatterIndex = RMSE/Y_mean\n",
        "\n",
        "#Outputting various metrics of success for the model\n",
        "print(\"R Squared:\",RSquared)\n",
        "print(\"Mean Absolute Error:\",MeanAbsoluteError)\n",
        "print(\"Mean Squared Error:\",MeanSquaredError)\n",
        "print(\"Root Mean Squared Error:\",RMSE)\n",
        "print(\"Scatter Index:\",ScatterIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC3zEEdxkdUZ",
        "outputId": "1cbf58d6-f292-4bed-892f-c9b9c2454830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R Squared: 0.42474918014729024\n",
            "Mean Absolute Error: 334.5745863545913\n",
            "Mean Squared Error: 179177.7380348018\n",
            "Root Mean Squared Error: 423.2939144788191\n",
            "Scatter Index: 0.5055971600661916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regression (All Features)**"
      ],
      "metadata": {
        "id": "w348eKICThFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RandomForestRegAll = RandomForestRegressor(random_state=254)\n",
        "RandomForestRegAll.fit(X_train_Scaled, Y_train)\n",
        "\n",
        "# Parameter grid for GridSearch\n",
        "ParameterGrid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "# Set up the grid search\n",
        "Search = GridSearchCV(estimator=RandomForestRegAll, param_grid=ParameterGrid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit grid search to the training data\n",
        "Search.fit(X_train_Scaled, Y_train)\n",
        "\n",
        "# Retrieve the best parameters and model\n",
        "BestParameters = Search.best_params_\n",
        "print(\"Best Parameters:\", BestParameters)\n",
        "\n",
        "#Declaring the best model from the grid search and using it to make predictions\n",
        "BestModel = Search.best_estimator_\n",
        "Predictions = BestModel.predict(X_test_Scaled)\n",
        "\n",
        "#Calculating the mean ranking present in the test set\n",
        "Y_mean = np.mean(Y_test)\n",
        "\n",
        "#Calculating various metrics of success for the model\n",
        "RSquared = BestModel.score(X_test_Scaled, Y_test)\n",
        "MeanAbsoluteError = mean_absolute_error(Y_test, Predictions)\n",
        "MeanSquaredError = mean_squared_error(Y_test, Predictions)\n",
        "RMSE = np.sqrt(MeanSquaredError)\n",
        "ScatterIndex = RMSE/Y_mean\n",
        "\n",
        "#Outputting various metrics of success for the model\n",
        "print(\"R Squared:\",RSquared)\n",
        "print(\"Mean Absolute Error:\",MeanAbsoluteError)\n",
        "print(\"Mean Squared Error:\",MeanSquaredError)\n",
        "print(\"Root Mean Squared Error:\",RMSE)\n",
        "print(\"Scatter Index:\",ScatterIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBa1u06-nIRM",
        "outputId": "4f867d0b-de59-4a7b-cc79-e6c520befc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "R Squared: 0.6523875682036129\n",
            "Mean Absolute Error: 231.35901741538513\n",
            "Mean Squared Error: 108273.48191872389\n",
            "Root Mean Squared Error: 329.04936091523393\n",
            "Scatter Index: 0.39302814595191227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network (All Features)**"
      ],
      "metadata": {
        "id": "xv1fFx6GUOXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the neural network\n",
        "NeuralNetworkAll = Sequential()\n",
        "NeuralNetworkAll.add(Dense(64, input_dim=X_train_Scaled.shape[1], activation='relu'))\n",
        "NeuralNetworkAll.add(Dense(128, activation='relu'))\n",
        "NeuralNetworkAll.add(Dense(64, activation='relu'))\n",
        "NeuralNetworkAll.add(Dropout(rate=0.3))\n",
        "NeuralNetworkAll.add(Dense(32, activation='relu'))\n",
        "NeuralNetworkAll.add(Dense(1))\n",
        "\n",
        "#Declaring an Adam optimiser\n",
        "Optimiser = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "#Declaring an early stopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "#Declaring a learning rate scheduler\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
        "\n",
        "#Compiling the neural network\n",
        "NeuralNetworkAll.compile(optimizer=Optimiser, loss='mean_squared_error')\n",
        "\n",
        "#Training the neural network\n",
        "History = NeuralNetworkAll.fit(X_train_Scaled, Y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "#Evaluating the neural network on the test dataset\n",
        "TestRMSE = NeuralNetworkAll.evaluate(X_test_Scaled, Y_test)\n",
        "\n",
        "#Calculating the mean ranking within the test set\n",
        "Y_mean = np.mean(Y_test)\n",
        "\n",
        "#Making predictions with the neural network\n",
        "Predictions = NeuralNetworkAll.predict(X_test_Scaled)\n",
        "\n",
        "#Calculating various metrics of success for the model\n",
        "RSquared = r2_score(Y_test, Predictions)\n",
        "MeanAbsoluteError = mean_absolute_error(Y_test, Predictions)\n",
        "MeanSquaredError = mean_squared_error(Y_test, Predictions)\n",
        "RMSE = np.sqrt(MeanSquaredError)\n",
        "ScatterIndex = RMSE/Y_mean\n",
        "\n",
        "#Outputting various metrics of success for the model\n",
        "print(\"R Squared:\",RSquared)\n",
        "print(\"Mean Absolute Error:\",MeanAbsoluteError)\n",
        "print(\"Mean Squared Error:\",MeanSquaredError)\n",
        "print(\"Root Mean Squared Error:\",RMSE)\n",
        "print(\"Scatter Index:\",ScatterIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f_z4j-wURaG",
        "outputId": "34e8907a-f3c2-4b86-ee26-cff23ab2ceb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1088154.7500 - val_loss: 912335.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1070244.8750 - val_loss: 909245.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1110997.8750 - val_loss: 898323.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1010329.5625 - val_loss: 864911.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 978594.5000 - val_loss: 779556.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 843915.1250 - val_loss: 619784.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 712394.6250 - val_loss: 447644.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 510981.1875 - val_loss: 411784.4062 - learning_rate: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 452093.0000 - val_loss: 410145.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 440145.4688 - val_loss: 399065.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 430471.6562 - val_loss: 398285.3125 - learning_rate: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 445010.7188 - val_loss: 390258.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 413650.5312 - val_loss: 379212.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 416892.5000 - val_loss: 372442.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 438668.8125 - val_loss: 371852.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 415918.6875 - val_loss: 370612.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 17/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 426527.9062 - val_loss: 364920.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 18/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 412133.8125 - val_loss: 360379.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 19/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 421352.6875 - val_loss: 358239.3750 - learning_rate: 5.0000e-04\n",
            "Epoch 20/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 395490.7812 - val_loss: 354606.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 21/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 385264.3750 - val_loss: 348080.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 22/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 387299.3750 - val_loss: 344059.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 23/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 368192.4375 - val_loss: 342461.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 24/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 370434.5938 - val_loss: 338270.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 25/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 372835.6250 - val_loss: 330964.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 26/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 355422.3438 - val_loss: 325417.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 27/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 356663.2500 - val_loss: 323145.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 28/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 357620.5000 - val_loss: 316641.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 29/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 350559.7812 - val_loss: 311031.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 30/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 356056.2500 - val_loss: 308152.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 31/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 318818.9688 - val_loss: 302269.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 32/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 331570.5000 - val_loss: 299271.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 33/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 323512.6250 - val_loss: 290016.3125 - learning_rate: 5.0000e-04\n",
            "Epoch 34/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 324261.9375 - val_loss: 285098.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 288404.0625 - val_loss: 283351.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 36/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 307175.8438 - val_loss: 275914.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 37/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 288240.5625 - val_loss: 271396.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 38/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 296385.4375 - val_loss: 262990.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 39/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 292581.9688 - val_loss: 257579.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 40/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 272076.8125 - val_loss: 254282.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 279134.4688 - val_loss: 253641.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 42/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 266846.0312 - val_loss: 245244.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 43/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 265731.3125 - val_loss: 240823.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 44/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 258941.3438 - val_loss: 236699.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 45/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 261763.0469 - val_loss: 233610.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 46/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 254778.2812 - val_loss: 229378.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 47/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 249055.2656 - val_loss: 228412.3906 - learning_rate: 5.0000e-04\n",
            "Epoch 48/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 235374.9844 - val_loss: 222657.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 49/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 236486.9844 - val_loss: 218196.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 50/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 233156.2656 - val_loss: 216220.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 51/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 238226.1094 - val_loss: 212947.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 52/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 220100.5625 - val_loss: 210482.3594 - learning_rate: 5.0000e-04\n",
            "Epoch 53/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 215381.2656 - val_loss: 208397.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 54/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 237063.9219 - val_loss: 205995.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 55/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 220949.3594 - val_loss: 201826.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 56/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 225025.1562 - val_loss: 199617.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 57/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 217538.2812 - val_loss: 198195.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 58/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 218042.4375 - val_loss: 195436.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 59/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 210427.4531 - val_loss: 193179.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 60/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 212695.1562 - val_loss: 191441.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 61/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 218378.6719 - val_loss: 188936.3594 - learning_rate: 5.0000e-04\n",
            "Epoch 62/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 215321.7656 - val_loss: 186670.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 63/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 211473.6875 - val_loss: 184608.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 64/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 205520.9062 - val_loss: 181921.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 65/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 198124.4688 - val_loss: 180090.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 66/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 216174.7500 - val_loss: 177696.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 67/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 201740.6719 - val_loss: 175318.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 68/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 210640.2969 - val_loss: 173443.7656 - learning_rate: 5.0000e-04\n",
            "Epoch 69/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 203540.3750 - val_loss: 171927.6094 - learning_rate: 5.0000e-04\n",
            "Epoch 70/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 197764.0625 - val_loss: 169925.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 71/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 195946.4688 - val_loss: 168468.8594 - learning_rate: 5.0000e-04\n",
            "Epoch 72/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 186801.5156 - val_loss: 167650.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 73/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 174800.3438 - val_loss: 165192.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 74/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 200566.8438 - val_loss: 163338.4062 - learning_rate: 5.0000e-04\n",
            "Epoch 75/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 193720.6719 - val_loss: 161882.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 76/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 177039.8906 - val_loss: 160656.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 77/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177358.0625 - val_loss: 159268.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 78/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 181695.7656 - val_loss: 158144.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 79/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 178033.2500 - val_loss: 156591.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 80/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188152.2500 - val_loss: 155231.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 81/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177217.2812 - val_loss: 153931.7344 - learning_rate: 5.0000e-04\n",
            "Epoch 82/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 183350.2969 - val_loss: 152773.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 83/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172190.6562 - val_loss: 151677.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 84/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 170591.1406 - val_loss: 150309.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 85/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 170253.6562 - val_loss: 149261.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 86/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 149166.4844 - val_loss: 148210.8594 - learning_rate: 5.0000e-04\n",
            "Epoch 87/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 169998.4219 - val_loss: 146844.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 88/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 158015.0469 - val_loss: 146769.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 89/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 163979.3906 - val_loss: 145238.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 90/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 148370.7031 - val_loss: 144578.2344 - learning_rate: 5.0000e-04\n",
            "Epoch 91/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 171454.4062 - val_loss: 143742.4844 - learning_rate: 5.0000e-04\n",
            "Epoch 92/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 158676.9219 - val_loss: 142538.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 93/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182548.8594 - val_loss: 142589.1562 - learning_rate: 5.0000e-04\n",
            "Epoch 94/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 164537.6250 - val_loss: 141032.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 95/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 167375.3594 - val_loss: 140891.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 96/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 166710.4688 - val_loss: 141153.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 97/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 156601.9062 - val_loss: 139132.7188 - learning_rate: 5.0000e-04\n",
            "Epoch 98/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 169906.6406 - val_loss: 138403.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 155053.9375 - val_loss: 137702.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 159156.5156 - val_loss: 136345.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 151990.8906 - val_loss: 137213.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 153232.3281 - val_loss: 137160.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 163538.3125 - val_loss: 135047.6406 - learning_rate: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 163019.2969 - val_loss: 135166.3594 - learning_rate: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 141728.0000 - val_loss: 133888.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 152485.4375 - val_loss: 135104.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 160511.7344 - val_loss: 132985.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 151248.5625 - val_loss: 132445.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 144722.6875 - val_loss: 131933.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 144731.3438 - val_loss: 131536.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 144342.8906 - val_loss: 131263.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 153566.3750 - val_loss: 130556.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 150520.5938 - val_loss: 130057.5234 - learning_rate: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 158304.1406 - val_loss: 129459.2344 - learning_rate: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 137261.6250 - val_loss: 129422.6953 - learning_rate: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 150004.7188 - val_loss: 129063.1641 - learning_rate: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 157797.6562 - val_loss: 129299.9922 - learning_rate: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 146741.7656 - val_loss: 127693.7109 - learning_rate: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 142552.2656 - val_loss: 127445.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 157818.7031 - val_loss: 127027.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 141417.7031 - val_loss: 126495.3906 - learning_rate: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 156630.6562 - val_loss: 128186.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 151379.5625 - val_loss: 126464.3203 - learning_rate: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 147703.4688 - val_loss: 126007.1328 - learning_rate: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 144892.3750 - val_loss: 125367.7188 - learning_rate: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 151703.6719 - val_loss: 126104.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 143009.8594 - val_loss: 124701.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 144146.0938 - val_loss: 126896.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 149265.0156 - val_loss: 124118.4766 - learning_rate: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 153325.2969 - val_loss: 123874.1328 - learning_rate: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 137898.2969 - val_loss: 124722.7578 - learning_rate: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 148951.8281 - val_loss: 123156.3203 - learning_rate: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 139609.4531 - val_loss: 122652.2266 - learning_rate: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 134261.9375 - val_loss: 122111.9453 - learning_rate: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 138659.7656 - val_loss: 122921.9922 - learning_rate: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 149263.7031 - val_loss: 122037.5781 - learning_rate: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 136737.7031 - val_loss: 121760.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 143159.2344 - val_loss: 120969.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 132110.2500 - val_loss: 121267.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 149957.0312 - val_loss: 124492.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 143767.8594 - val_loss: 121021.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 145705.8750 - val_loss: 124147.7188 - learning_rate: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 137166.8281 - val_loss: 119993.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 143686.7188 - val_loss: 120287.4922 - learning_rate: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 136990.4688 - val_loss: 119792.4062 - learning_rate: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 132961.2812 - val_loss: 120399.7344 - learning_rate: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 139501.5469 - val_loss: 120197.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128639.3438 - val_loss: 118603.1953 - learning_rate: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 142515.4062 - val_loss: 119398.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 159485.7500 - val_loss: 118336.6328 - learning_rate: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 135878.2031 - val_loss: 117988.2812 - learning_rate: 5.0000e-04\n",
            "Epoch 152/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 138186.7344 - val_loss: 118286.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 153/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 143219.2969 - val_loss: 118154.6953 - learning_rate: 5.0000e-04\n",
            "Epoch 154/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 132602.7031 - val_loss: 118226.3203 - learning_rate: 5.0000e-04\n",
            "Epoch 155/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 139730.2656 - val_loss: 117219.9453 - learning_rate: 5.0000e-04\n",
            "Epoch 156/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 130664.7344 - val_loss: 117805.1797 - learning_rate: 5.0000e-04\n",
            "Epoch 157/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 140706.4219 - val_loss: 118005.3906 - learning_rate: 5.0000e-04\n",
            "Epoch 158/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 138161.3438 - val_loss: 117951.4219 - learning_rate: 5.0000e-04\n",
            "Epoch 159/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 134467.0781 - val_loss: 116375.8828 - learning_rate: 5.0000e-04\n",
            "Epoch 160/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 128871.6641 - val_loss: 117260.6016 - learning_rate: 5.0000e-04\n",
            "Epoch 161/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 140208.4062 - val_loss: 116263.3359 - learning_rate: 5.0000e-04\n",
            "Epoch 162/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 135513.6562 - val_loss: 116607.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 163/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 134684.7969 - val_loss: 116648.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 164/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 140942.4375 - val_loss: 115732.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 165/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 139204.5156 - val_loss: 115827.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 166/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 138316.6406 - val_loss: 115854.6953 - learning_rate: 5.0000e-04\n",
            "Epoch 167/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 131942.2969 - val_loss: 115595.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 168/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 139700.2344 - val_loss: 115114.2891 - learning_rate: 5.0000e-04\n",
            "Epoch 169/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 135062.2656 - val_loss: 115785.4922 - learning_rate: 5.0000e-04\n",
            "Epoch 170/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 132248.2969 - val_loss: 115218.3828 - learning_rate: 5.0000e-04\n",
            "Epoch 171/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 131867.1719 - val_loss: 115165.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 172/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 141843.0469 - val_loss: 115249.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 173/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 133819.1094 - val_loss: 116778.7344 - learning_rate: 5.0000e-04\n",
            "Epoch 174/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 141626.0938 - val_loss: 114956.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 175/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 136251.6250 - val_loss: 114832.9609 - learning_rate: 5.0000e-04\n",
            "Epoch 176/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 141624.9844 - val_loss: 114390.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 177/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 134038.1250 - val_loss: 115438.5781 - learning_rate: 5.0000e-04\n",
            "Epoch 178/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 139775.9531 - val_loss: 113884.0391 - learning_rate: 5.0000e-04\n",
            "Epoch 179/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 120970.2656 - val_loss: 114632.1641 - learning_rate: 5.0000e-04\n",
            "Epoch 180/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 131694.7188 - val_loss: 114094.8672 - learning_rate: 5.0000e-04\n",
            "Epoch 181/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 134625.4531 - val_loss: 113732.1484 - learning_rate: 5.0000e-04\n",
            "Epoch 182/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 123478.2188 - val_loss: 115752.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 183/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 132851.7500 - val_loss: 114037.8984 - learning_rate: 5.0000e-04\n",
            "Epoch 184/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 129235.0078 - val_loss: 114216.9531 - learning_rate: 5.0000e-04\n",
            "Epoch 185/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 131709.9688 - val_loss: 113029.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 186/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 129862.3906 - val_loss: 114212.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 187/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 137921.1562 - val_loss: 112745.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 188/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126141.1016 - val_loss: 113154.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 189/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 135767.7344 - val_loss: 112657.9766 - learning_rate: 5.0000e-04\n",
            "Epoch 190/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 138758.8281 - val_loss: 114816.5156 - learning_rate: 5.0000e-04\n",
            "Epoch 191/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 127208.7734 - val_loss: 112787.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 192/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 119126.0000 - val_loss: 112325.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 193/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 133316.2188 - val_loss: 112115.2734 - learning_rate: 5.0000e-04\n",
            "Epoch 194/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 122055.1562 - val_loss: 112891.3125 - learning_rate: 5.0000e-04\n",
            "Epoch 195/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128140.5859 - val_loss: 111933.5234 - learning_rate: 5.0000e-04\n",
            "Epoch 196/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126080.1719 - val_loss: 111953.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 197/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 139063.5938 - val_loss: 112657.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 198/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 129918.7891 - val_loss: 111956.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 199/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 127599.7188 - val_loss: 111676.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 200/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 136382.4062 - val_loss: 111519.2109 - learning_rate: 5.0000e-04\n",
            "Epoch 201/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 137506.7031 - val_loss: 114414.9922 - learning_rate: 5.0000e-04\n",
            "Epoch 202/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 126480.2422 - val_loss: 111940.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 203/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 135614.3125 - val_loss: 111569.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 204/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 131146.2969 - val_loss: 111878.8672 - learning_rate: 5.0000e-04\n",
            "Epoch 205/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 127046.6562 - val_loss: 111206.0391 - learning_rate: 5.0000e-04\n",
            "Epoch 206/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 126003.2266 - val_loss: 110919.0078 - learning_rate: 5.0000e-04\n",
            "Epoch 207/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 131642.5312 - val_loss: 116337.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 208/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 141884.8750 - val_loss: 110754.5391 - learning_rate: 5.0000e-04\n",
            "Epoch 209/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 125706.4453 - val_loss: 114388.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 210/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 125365.5547 - val_loss: 112381.3984 - learning_rate: 5.0000e-04\n",
            "Epoch 211/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 124238.9531 - val_loss: 111493.1797 - learning_rate: 5.0000e-04\n",
            "Epoch 212/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 117333.2422 - val_loss: 111567.9141 - learning_rate: 5.0000e-04\n",
            "Epoch 213/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 132526.1875 - val_loss: 110593.0547 - learning_rate: 5.0000e-04\n",
            "Epoch 214/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 129694.1406 - val_loss: 110879.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 215/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 123099.1719 - val_loss: 112402.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 216/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 130308.0000 - val_loss: 110781.1797 - learning_rate: 5.0000e-04\n",
            "Epoch 217/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 127153.0000 - val_loss: 110660.5156 - learning_rate: 5.0000e-04\n",
            "Epoch 218/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 137834.5938 - val_loss: 110970.1016 - learning_rate: 5.0000e-04\n",
            "Epoch 219/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 134355.2656 - val_loss: 110173.8047 - learning_rate: 5.0000e-04\n",
            "Epoch 220/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 125919.8125 - val_loss: 110220.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 221/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 119063.1406 - val_loss: 110331.8672 - learning_rate: 5.0000e-04\n",
            "Epoch 222/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 141200.0312 - val_loss: 110080.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 223/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 137339.5938 - val_loss: 109804.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 224/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 123875.8125 - val_loss: 110947.5859 - learning_rate: 5.0000e-04\n",
            "Epoch 225/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126143.9609 - val_loss: 110935.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 226/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 125596.1875 - val_loss: 109414.0703 - learning_rate: 5.0000e-04\n",
            "Epoch 227/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 148127.9844 - val_loss: 110696.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 228/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 134425.8281 - val_loss: 110878.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 229/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 138153.7031 - val_loss: 110069.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 230/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 127534.4297 - val_loss: 109305.2812 - learning_rate: 5.0000e-04\n",
            "Epoch 231/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 138905.4062 - val_loss: 111555.1172 - learning_rate: 5.0000e-04\n",
            "Epoch 232/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 155405.1406 - val_loss: 109224.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 233/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 132634.3281 - val_loss: 109869.4297 - learning_rate: 5.0000e-04\n",
            "Epoch 234/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 120968.6406 - val_loss: 110507.9609 - learning_rate: 5.0000e-04\n",
            "Epoch 235/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 138210.2344 - val_loss: 108972.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 236/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 124170.5312 - val_loss: 110034.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 237/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 123694.4766 - val_loss: 109183.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 238/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 123577.9453 - val_loss: 110489.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 239/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 137621.3594 - val_loss: 108772.0234 - learning_rate: 5.0000e-04\n",
            "Epoch 240/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 122007.2188 - val_loss: 109489.9297 - learning_rate: 5.0000e-04\n",
            "Epoch 241/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 124599.7656 - val_loss: 108543.8047 - learning_rate: 5.0000e-04\n",
            "Epoch 242/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 127009.7422 - val_loss: 110927.4609 - learning_rate: 5.0000e-04\n",
            "Epoch 243/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 121508.4766 - val_loss: 109034.2578 - learning_rate: 5.0000e-04\n",
            "Epoch 244/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 125342.7422 - val_loss: 108910.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 245/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 139327.1406 - val_loss: 108727.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 246/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 123796.7422 - val_loss: 109462.1562 - learning_rate: 5.0000e-04\n",
            "Epoch 247/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126035.7266 - val_loss: 109927.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 248/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 132083.7969 - val_loss: 108214.2578 - learning_rate: 5.0000e-04\n",
            "Epoch 249/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 127674.1484 - val_loss: 108231.8516 - learning_rate: 5.0000e-04\n",
            "Epoch 250/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 125942.0391 - val_loss: 108705.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 251/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 123594.8438 - val_loss: 108331.8203 - learning_rate: 5.0000e-04\n",
            "Epoch 252/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 131415.5469 - val_loss: 112011.6406 - learning_rate: 5.0000e-04\n",
            "Epoch 253/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 129429.3750 - val_loss: 107988.3828 - learning_rate: 5.0000e-04\n",
            "Epoch 254/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 123193.2656 - val_loss: 108163.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 255/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 128337.4141 - val_loss: 108276.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 256/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 129903.2266 - val_loss: 109585.9453 - learning_rate: 5.0000e-04\n",
            "Epoch 257/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 121114.4297 - val_loss: 108667.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 258/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 117843.7734 - val_loss: 108775.5234 - learning_rate: 5.0000e-04\n",
            "Epoch 259/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 145245.3125 - val_loss: 108290.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 260/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 135666.7812 - val_loss: 109273.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 261/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 127101.3438 - val_loss: 108895.7344 - learning_rate: 5.0000e-04\n",
            "Epoch 262/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 115823.6641 - val_loss: 108524.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 263/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 128107.0156 - val_loss: 108840.8359 - learning_rate: 5.0000e-04\n",
            "Epoch 264/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 121304.9766 - val_loss: 108623.0078 - learning_rate: 2.5000e-04\n",
            "Epoch 265/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 110376.1094 - val_loss: 108191.5781 - learning_rate: 2.5000e-04\n",
            "Epoch 266/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 119382.1641 - val_loss: 108293.6172 - learning_rate: 2.5000e-04\n",
            "Epoch 267/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 138405.6250 - val_loss: 108961.2734 - learning_rate: 2.5000e-04\n",
            "Epoch 268/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 133955.8281 - val_loss: 108567.2266 - learning_rate: 2.5000e-04\n",
            "Epoch 269/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126356.9219 - val_loss: 108841.8828 - learning_rate: 2.5000e-04\n",
            "Epoch 270/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 125462.3203 - val_loss: 108089.8438 - learning_rate: 2.5000e-04\n",
            "Epoch 271/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 122930.2734 - val_loss: 108534.2891 - learning_rate: 2.5000e-04\n",
            "Epoch 272/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 131203.3906 - val_loss: 108315.6562 - learning_rate: 2.5000e-04\n",
            "Epoch 273/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 129425.6875 - val_loss: 108484.3594 - learning_rate: 2.5000e-04\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 154644.6562 \n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "R Squared: 0.5449992418289185\n",
            "Mean Absolute Error: 291.17926025390625\n",
            "Mean Squared Error: 141722.515625\n",
            "Root Mean Squared Error: 376.4605100472027\n",
            "Scatter Index: 0.4496576923183237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection using Correlation**"
      ],
      "metadata": {
        "id": "PpeVYk9WefUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the predictors' correlation with the target and removing features that do not share a significant correlation with the target\n",
        "Correlation = DataFrame.corr()\n",
        "CorrelationWithTarget = abs(Correlation[\"Ranking\"])\n",
        "CorrelatedPredictors = CorrelationWithTarget[CorrelationWithTarget>0.3].index.values.tolist()\n",
        "CorrelatedPredictors.remove(\"Ranking\")\n",
        "print(\"Correlated:\",CorrelatedPredictors)\n",
        "X_Correlated = DataFrame[CorrelatedPredictors]\n",
        "Y_Correlated = DataFrame[\"Ranking\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVhIClk_e0yG",
        "outputId": "43dbd4dc-07b1-4c08-e295-8261178cee92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlated: ['Height', 'Speed', 'Length']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing/Train-Test Split for Correlated Features Only**"
      ],
      "metadata": {
        "id": "BtEAO3yVf28G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing a train/test split so that a holdout test set can be provided\n",
        "X_Correlated_train, X_Correlated_test, Y_Correlated_train, Y_Correlated_test = train_test_split(X_Correlated, Y_Correlated, test_size=0.2, random_state=254)"
      ],
      "metadata": {
        "id": "FI6rZfukf8L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling features so that larger features do not have undue influence on the models\n",
        "CorrelatedFeatureScaler = MinMaxScaler()\n",
        "X_Correlated_train_Scaled = CorrelatedFeatureScaler.fit_transform(X_Correlated_train)\n",
        "X_Correlated_test_Scaled = CorrelatedFeatureScaler.transform(X_Correlated_test)"
      ],
      "metadata": {
        "id": "8tS1BA-VgOvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression (Correlated Features)**"
      ],
      "metadata": {
        "id": "fcvjl9FMgt7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring a linear regression model and fitting it to the training set\n",
        "LinRegCorrelated = LinearRegression()\n",
        "LinRegCorrelated.fit(X_Correlated_train_Scaled, Y_Correlated_train)\n",
        "\n",
        "#Making predictions on the test set\n",
        "Predictions = LinRegCorrelated.predict(X_Correlated_test_Scaled)\n",
        "\n",
        "#Calculating the mean ranking in the test set\n",
        "Y_Correlated_mean = np.mean(Y_Correlated_test)\n",
        "\n",
        "#Calculating various metrics of success for the model\n",
        "RSquared = LinRegCorrelated.score(X_Correlated_test_Scaled, Y_test)\n",
        "MeanAbsoluteError = mean_absolute_error(Y_Correlated_test, Predictions)\n",
        "MeanSquaredError = mean_squared_error(Y_Correlated_test, Predictions)\n",
        "RMSE = np.sqrt(MeanSquaredError)\n",
        "ScatterIndex = RMSE/Y_Correlated_mean\n",
        "\n",
        "#Outputting various metrics of success for the model\n",
        "print(\"R Squared:\",RSquared)\n",
        "print(\"Mean Absolute Error:\",MeanAbsoluteError)\n",
        "print(\"Mean Squared Error:\",MeanSquaredError)\n",
        "print(\"Root Mean Squared Error:\",RMSE)\n",
        "print(\"Scatter Index:\",ScatterIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ivkgwdxgyge",
        "outputId": "f1bddb5c-6c49-43f0-ac29-4efdbcf2d695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R Squared: 0.3676886353251714\n",
            "Mean Absolute Error: 354.1167682172174\n",
            "Mean Squared Error: 196950.81892302804\n",
            "Root Mean Squared Error: 443.79141375541286\n",
            "Scatter Index: 0.5300800951338139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regression (Correlated Features)**"
      ],
      "metadata": {
        "id": "TuDUlWgDhNrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring a random forest model and fitting it to the training data\n",
        "RandomForestRegCorrelated = RandomForestRegressor(random_state=254)\n",
        "RandomForestRegCorrelated.fit(X_Correlated_train_Scaled, Y_train)\n",
        "\n",
        "# Parameter grid for GridSearch\n",
        "ParameterGrid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "#Setting up the grid search\n",
        "Search = GridSearchCV(estimator=RandomForestRegCorrelated, param_grid=ParameterGrid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "\n",
        "#Fitting grid search to the training data\n",
        "Search.fit(X_Correlated_train_Scaled, Y_Correlated_train)\n",
        "\n",
        "#Retrieving the best parameters\n",
        "BestParameters = Search.best_params_\n",
        "print(\"Best Parameters:\", BestParameters)\n",
        "\n",
        "#Retrieving the best model and making predictions on the test set with it\n",
        "BestModel = Search.best_estimator_\n",
        "Predictions = BestModel.predict(X_Correlated_test_Scaled)\n",
        "\n",
        "#Calculating the mean ranking within the test set\n",
        "Y_Correlated_mean = np.mean(Y_Correlated_test)\n",
        "\n",
        "#Calculating various metrics of success for the model\n",
        "RSquared = BestModel.score(X_Correlated_test_Scaled, Y_Correlated_test)\n",
        "MeanAbsoluteError = mean_absolute_error(Y_Correlated_test, Predictions)\n",
        "MeanSquaredError = mean_squared_error(Y_Correlated_test, Predictions)\n",
        "RMSE = np.sqrt(MeanSquaredError)\n",
        "ScatterIndex = RMSE/Y_mean\n",
        "\n",
        "#Outputting various metrics of success for the model\n",
        "print(\"R Squared:\",RSquared)\n",
        "print(\"Mean Absolute Error:\",MeanAbsoluteError)\n",
        "print(\"Mean Squared Error:\",MeanSquaredError)\n",
        "print(\"Root Mean Squared Error:\",RMSE)\n",
        "print(\"Scatter Index:\",ScatterIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxojjT-rhR6B",
        "outputId": "d92a4c9b-e65a-4a22-c100-82ac63dedbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "R Squared: 0.5828430240248579\n",
            "Mean Absolute Error: 260.0509356535416\n",
            "Mean Squared Error: 129935.04881888267\n",
            "Root Mean Squared Error: 360.46504521088127\n",
            "Scatter Index: 0.4305521457499536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network (Correlated Features)**"
      ],
      "metadata": {
        "id": "t9fH9A1bi-Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the neural network\n",
        "NeuralNetworkCorrelated = Sequential()\n",
        "NeuralNetworkCorrelated.add(Dense(64, input_dim=X_Correlated_train_Scaled.shape[1], activation='relu'))\n",
        "NeuralNetworkCorrelated.add(Dense(128, activation='relu'))\n",
        "NeuralNetworkCorrelated.add(Dense(64, activation='relu'))\n",
        "NeuralNetworkCorrelated.add(Dropout(rate=0.3))  # Dropout regularization\n",
        "NeuralNetworkCorrelated.add(Dense(32, activation='relu'))\n",
        "NeuralNetworkCorrelated.add(Dense(1))  # Output layer\n",
        "\n",
        "#Declaring an optimiser\n",
        "Optimiser = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "#Declaring an early stopping callback\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "#Declaring a learning rate scheduler\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
        "\n",
        "#Compiling the neural network\n",
        "NeuralNetworkCorrelated.compile(optimizer=Optimiser, loss='mean_squared_error')\n",
        "\n",
        "#Training the neural network\n",
        "History = NeuralNetworkCorrelated.fit(X_Correlated_train_Scaled, Y_Correlated_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "#Evaluating the neural network\n",
        "TestRMSE = NeuralNetworkCorrelated.evaluate(X_Correlated_test_Scaled, Y_Correlated_test)\n",
        "\n",
        "#Calculating the mean ranking value within the test set\n",
        "Y_Correlated_mean = np.mean(Y_Correlated_test)\n",
        "\n",
        "#Making predictions on the test set with the neural network\n",
        "Predictions = NeuralNetworkCorrelated.predict(X_Correlated_test_Scaled)\n",
        "\n",
        "#Calculating various metrics of success for the model\n",
        "RSquared = r2_score(Y_Correlated_test, Predictions)\n",
        "MeanAbsoluteError = mean_absolute_error(Y_Correlated_test, Predictions)\n",
        "MeanSquaredError = mean_squared_error(Y_Correlated_test, Predictions)\n",
        "RMSE = np.sqrt(MeanSquaredError)\n",
        "ScatterIndex = RMSE/Y_Correlated_mean\n",
        "\n",
        "#Outputting various metrics of success for the model\n",
        "print(\"R Squared:\",RSquared)\n",
        "print(\"Mean Absolute Error:\",MeanAbsoluteError)\n",
        "print(\"Mean Squared Error:\",MeanSquaredError)\n",
        "print(\"Root Mean Squared Error:\",RMSE)\n",
        "print(\"Scatter Index:\",ScatterIndex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMmR7WCGi4k3",
        "outputId": "de473f6f-dc6f-4d01-f56b-c314ba2b508f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 1059269.8750 - val_loss: 913007.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1056146.3750 - val_loss: 911581.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1066765.2500 - val_loss: 905498.3750 - learning_rate: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1030049.4375 - val_loss: 882432.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1061356.8750 - val_loss: 816922.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 905472.6875 - val_loss: 673966.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 774373.1875 - val_loss: 496340.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 573858.0000 - val_loss: 443890.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 500637.5312 - val_loss: 434809.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 467882.0938 - val_loss: 414676.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 473631.0938 - val_loss: 402232.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 460162.5312 - val_loss: 395450.2812 - learning_rate: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 435130.4688 - val_loss: 386131.2812 - learning_rate: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 410946.6250 - val_loss: 373714.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 402041.0000 - val_loss: 358954.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 407736.3125 - val_loss: 348779.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 17/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 417997.2812 - val_loss: 335853.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 18/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 365627.8125 - val_loss: 326409.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 19/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 365596.6562 - val_loss: 313169.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 20/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 346055.8125 - val_loss: 302814.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 21/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 332084.3750 - val_loss: 291052.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 22/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 289402.7500 - val_loss: 279780.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 23/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 307284.2812 - val_loss: 265952.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 24/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 298090.3125 - val_loss: 259033.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 25/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 292404.9062 - val_loss: 243934.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 26/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 254817.4219 - val_loss: 232074.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 27/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 259299.0000 - val_loss: 222952.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 28/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 243454.1875 - val_loss: 213631.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 29/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 223212.2344 - val_loss: 203930.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 30/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 224383.7812 - val_loss: 197510.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 31/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 239316.1094 - val_loss: 191583.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 32/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 211461.7188 - val_loss: 187478.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 33/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 216127.0781 - val_loss: 182651.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 34/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 189306.0312 - val_loss: 178188.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 35/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 215553.0625 - val_loss: 175987.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 36/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 203337.5625 - val_loss: 173870.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 37/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 198437.9062 - val_loss: 172306.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 38/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 195628.6250 - val_loss: 171466.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 39/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184375.4219 - val_loss: 170510.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 40/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176129.9375 - val_loss: 170841.5781 - learning_rate: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 188197.7344 - val_loss: 170869.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 42/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 198726.4375 - val_loss: 169340.6406 - learning_rate: 5.0000e-04\n",
            "Epoch 43/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173504.0625 - val_loss: 169587.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 44/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 160602.4688 - val_loss: 168667.1562 - learning_rate: 5.0000e-04\n",
            "Epoch 45/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 185598.0938 - val_loss: 168627.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 46/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 184128.5625 - val_loss: 169019.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 47/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182251.3906 - val_loss: 168305.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 48/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 190186.9375 - val_loss: 168094.4219 - learning_rate: 5.0000e-04\n",
            "Epoch 49/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173559.0781 - val_loss: 168237.8594 - learning_rate: 5.0000e-04\n",
            "Epoch 50/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 183301.4219 - val_loss: 168053.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 51/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 197470.2500 - val_loss: 168566.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 52/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 178099.7500 - val_loss: 168038.9531 - learning_rate: 5.0000e-04\n",
            "Epoch 53/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 179822.9844 - val_loss: 167814.2344 - learning_rate: 5.0000e-04\n",
            "Epoch 54/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 193262.7656 - val_loss: 167904.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 55/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185717.7656 - val_loss: 167471.5156 - learning_rate: 5.0000e-04\n",
            "Epoch 56/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184683.7969 - val_loss: 167366.7188 - learning_rate: 5.0000e-04\n",
            "Epoch 57/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188765.7500 - val_loss: 167461.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 58/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184799.2812 - val_loss: 167212.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 59/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182599.5312 - val_loss: 167161.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 60/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 193998.7188 - val_loss: 167178.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 61/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 191228.3750 - val_loss: 167129.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 62/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177595.5469 - val_loss: 167984.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 63/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188741.9375 - val_loss: 167047.9219 - learning_rate: 5.0000e-04\n",
            "Epoch 64/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 192599.1094 - val_loss: 166919.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 65/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 195983.5625 - val_loss: 166874.6875 - learning_rate: 5.0000e-04\n",
            "Epoch 66/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185415.4375 - val_loss: 166831.1406 - learning_rate: 5.0000e-04\n",
            "Epoch 67/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 194005.0469 - val_loss: 166740.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 68/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 192490.9688 - val_loss: 167157.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 69/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184664.4688 - val_loss: 167455.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 70/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 186100.2500 - val_loss: 166879.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 71/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 183473.9375 - val_loss: 166465.6406 - learning_rate: 5.0000e-04\n",
            "Epoch 72/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184523.9375 - val_loss: 166601.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 73/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 163364.6406 - val_loss: 166278.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 74/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 182667.6094 - val_loss: 166792.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 75/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 177913.7031 - val_loss: 167015.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 76/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 168991.4062 - val_loss: 166362.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 77/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 183780.2812 - val_loss: 166389.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 78/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 205167.0625 - val_loss: 166061.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 79/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 195425.2969 - val_loss: 165999.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 80/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 190285.7500 - val_loss: 166119.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 81/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 185356.5312 - val_loss: 165942.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 82/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188642.2969 - val_loss: 166085.6719 - learning_rate: 5.0000e-04\n",
            "Epoch 83/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 181989.4062 - val_loss: 165870.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 84/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 189462.1875 - val_loss: 165712.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 85/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179733.4844 - val_loss: 165789.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 86/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184544.4531 - val_loss: 167228.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 87/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 187084.7500 - val_loss: 165882.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 88/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168935.2344 - val_loss: 166336.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 89/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177063.8438 - val_loss: 165681.5000 - learning_rate: 5.0000e-04\n",
            "Epoch 90/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 197226.5312 - val_loss: 165603.3125 - learning_rate: 5.0000e-04\n",
            "Epoch 91/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178897.2500 - val_loss: 165885.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 92/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 187996.0469 - val_loss: 165501.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 93/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173146.0312 - val_loss: 165477.9219 - learning_rate: 5.0000e-04\n",
            "Epoch 94/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 184111.6719 - val_loss: 165736.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 95/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175370.4531 - val_loss: 165550.6406 - learning_rate: 5.0000e-04\n",
            "Epoch 96/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176833.0000 - val_loss: 165321.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 97/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 169203.9219 - val_loss: 165281.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 98/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 204057.1875 - val_loss: 165373.1406 - learning_rate: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174191.4688 - val_loss: 165254.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182983.1094 - val_loss: 165799.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185659.1875 - val_loss: 165504.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176780.5938 - val_loss: 165372.4219 - learning_rate: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 193445.7812 - val_loss: 165262.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168099.3750 - val_loss: 165264.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 189692.5781 - val_loss: 166867.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 186810.2500 - val_loss: 165204.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 192428.6406 - val_loss: 165144.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 171355.2656 - val_loss: 165040.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 186413.4688 - val_loss: 165002.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 159703.2344 - val_loss: 165575.9219 - learning_rate: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184178.0000 - val_loss: 164974.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175376.1406 - val_loss: 164966.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 172166.6250 - val_loss: 165975.2344 - learning_rate: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 198598.3438 - val_loss: 164834.3125 - learning_rate: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176402.6562 - val_loss: 164859.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 180406.0781 - val_loss: 164772.6719 - learning_rate: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 195085.0625 - val_loss: 164950.1406 - learning_rate: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 192249.1562 - val_loss: 164875.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 170987.0000 - val_loss: 164827.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 185200.4219 - val_loss: 165101.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 183107.8906 - val_loss: 164533.5156 - learning_rate: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 193375.9062 - val_loss: 164847.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 187196.1250 - val_loss: 164660.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 191890.4219 - val_loss: 164649.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 191394.6250 - val_loss: 164846.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 167998.7969 - val_loss: 164462.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 187046.7812 - val_loss: 164563.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 181961.4062 - val_loss: 164391.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 180063.6406 - val_loss: 165000.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 184107.8125 - val_loss: 164374.2188 - learning_rate: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177850.6406 - val_loss: 164357.3750 - learning_rate: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 190126.9219 - val_loss: 164379.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 188522.8750 - val_loss: 164324.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174028.6875 - val_loss: 164351.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175249.8281 - val_loss: 164409.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 193460.4219 - val_loss: 164529.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 186914.8281 - val_loss: 164350.7031 - learning_rate: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 186664.3438 - val_loss: 164609.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 179958.7969 - val_loss: 164249.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175051.5156 - val_loss: 164305.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 189400.3750 - val_loss: 164143.1406 - learning_rate: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 209541.1562 - val_loss: 164115.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 197222.8594 - val_loss: 164126.7656 - learning_rate: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177110.5000 - val_loss: 164046.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177912.8594 - val_loss: 164256.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 164771.3438 - val_loss: 164124.7344 - learning_rate: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185060.1094 - val_loss: 163999.6719 - learning_rate: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 186812.6875 - val_loss: 163961.2344 - learning_rate: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184183.9062 - val_loss: 164248.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 201181.2344 - val_loss: 163986.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182913.9531 - val_loss: 163908.3594 - learning_rate: 5.0000e-04\n",
            "Epoch 152/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 208084.8125 - val_loss: 164504.9062 - learning_rate: 5.0000e-04\n",
            "Epoch 153/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184445.5625 - val_loss: 163909.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 154/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 195532.7656 - val_loss: 163884.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 155/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181499.9688 - val_loss: 163820.7812 - learning_rate: 5.0000e-04\n",
            "Epoch 156/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 176065.4062 - val_loss: 163821.3750 - learning_rate: 5.0000e-04\n",
            "Epoch 157/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 183566.3594 - val_loss: 163759.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 158/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171054.5938 - val_loss: 163721.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 159/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171744.6562 - val_loss: 163741.6719 - learning_rate: 5.0000e-04\n",
            "Epoch 160/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173250.2344 - val_loss: 163701.8906 - learning_rate: 5.0000e-04\n",
            "Epoch 161/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175975.4688 - val_loss: 163802.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 162/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 196991.7031 - val_loss: 164307.4062 - learning_rate: 5.0000e-04\n",
            "Epoch 163/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 177641.9531 - val_loss: 164091.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 164/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 190372.1562 - val_loss: 163780.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 165/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 201844.3438 - val_loss: 163943.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 166/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 184597.1094 - val_loss: 163616.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 167/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 182713.2344 - val_loss: 164239.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 168/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 182418.2031 - val_loss: 163692.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 169/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 177510.7656 - val_loss: 163518.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 170/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 198490.4219 - val_loss: 163551.8438 - learning_rate: 5.0000e-04\n",
            "Epoch 171/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 188104.5000 - val_loss: 163499.0625 - learning_rate: 5.0000e-04\n",
            "Epoch 172/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 186661.7812 - val_loss: 163477.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 173/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 172415.3906 - val_loss: 163755.1719 - learning_rate: 5.0000e-04\n",
            "Epoch 174/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 169179.1094 - val_loss: 163617.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 175/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184186.3125 - val_loss: 163331.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 176/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185212.5312 - val_loss: 163302.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 177/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175180.2500 - val_loss: 163494.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 178/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 189289.8281 - val_loss: 163230.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 179/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 188903.9375 - val_loss: 163740.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 180/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 181017.0938 - val_loss: 163236.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 181/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 167560.1875 - val_loss: 164031.1562 - learning_rate: 5.0000e-04\n",
            "Epoch 182/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181784.6719 - val_loss: 163149.2656 - learning_rate: 5.0000e-04\n",
            "Epoch 183/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 180767.4844 - val_loss: 163314.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 184/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182270.1094 - val_loss: 163155.0938 - learning_rate: 5.0000e-04\n",
            "Epoch 185/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 193159.7812 - val_loss: 163219.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 186/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 185312.9375 - val_loss: 163232.3906 - learning_rate: 5.0000e-04\n",
            "Epoch 187/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184177.0000 - val_loss: 163304.6719 - learning_rate: 5.0000e-04\n",
            "Epoch 188/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 172748.3125 - val_loss: 163477.5781 - learning_rate: 5.0000e-04\n",
            "Epoch 189/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184471.8125 - val_loss: 163208.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 190/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184577.7812 - val_loss: 163659.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 191/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 207633.1562 - val_loss: 163080.3281 - learning_rate: 5.0000e-04\n",
            "Epoch 192/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182395.3906 - val_loss: 163067.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 193/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 198633.9688 - val_loss: 163022.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 194/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172101.1719 - val_loss: 163154.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 195/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182492.8281 - val_loss: 163082.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 196/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 162114.1406 - val_loss: 163222.0781 - learning_rate: 5.0000e-04\n",
            "Epoch 197/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 190868.7656 - val_loss: 163001.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 198/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 163591.8750 - val_loss: 162932.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 199/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 198271.6875 - val_loss: 163089.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 200/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 190329.1719 - val_loss: 163039.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 201/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175389.5469 - val_loss: 162991.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 202/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 189749.3125 - val_loss: 162928.1406 - learning_rate: 5.0000e-04\n",
            "Epoch 203/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 159606.3594 - val_loss: 163905.3125 - learning_rate: 5.0000e-04\n",
            "Epoch 204/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175880.3125 - val_loss: 162830.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 205/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 200299.7344 - val_loss: 162815.5469 - learning_rate: 5.0000e-04\n",
            "Epoch 206/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178847.9531 - val_loss: 162749.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 207/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 183341.9531 - val_loss: 162755.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 208/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174459.2969 - val_loss: 163126.8281 - learning_rate: 5.0000e-04\n",
            "Epoch 209/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 196571.1094 - val_loss: 162875.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 210/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 192986.2031 - val_loss: 162735.2812 - learning_rate: 5.0000e-04\n",
            "Epoch 211/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 181019.8906 - val_loss: 163570.6094 - learning_rate: 5.0000e-04\n",
            "Epoch 212/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 195690.3438 - val_loss: 162720.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 213/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 183794.3594 - val_loss: 162827.5781 - learning_rate: 5.0000e-04\n",
            "Epoch 214/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 184582.7812 - val_loss: 163409.6719 - learning_rate: 5.0000e-04\n",
            "Epoch 215/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 173051.7031 - val_loss: 162686.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 216/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 191172.3125 - val_loss: 162682.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 217/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 189361.5000 - val_loss: 162695.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 218/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 190030.3750 - val_loss: 162683.4375 - learning_rate: 5.0000e-04\n",
            "Epoch 219/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188163.1719 - val_loss: 162698.8594 - learning_rate: 5.0000e-04\n",
            "Epoch 220/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175869.8750 - val_loss: 162691.5625 - learning_rate: 5.0000e-04\n",
            "Epoch 221/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 170558.5000 - val_loss: 163125.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 222/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 186283.0938 - val_loss: 162861.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 223/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 165907.3594 - val_loss: 163087.3438 - learning_rate: 5.0000e-04\n",
            "Epoch 224/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182661.8281 - val_loss: 162936.4844 - learning_rate: 5.0000e-04\n",
            "Epoch 225/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169238.0469 - val_loss: 162799.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 226/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184979.8125 - val_loss: 162633.4688 - learning_rate: 5.0000e-04\n",
            "Epoch 227/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 190277.9688 - val_loss: 162608.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 228/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180572.2812 - val_loss: 162499.9219 - learning_rate: 5.0000e-04\n",
            "Epoch 229/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 192102.6562 - val_loss: 162494.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 230/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181628.1562 - val_loss: 162535.3594 - learning_rate: 5.0000e-04\n",
            "Epoch 231/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175310.5000 - val_loss: 162639.2031 - learning_rate: 5.0000e-04\n",
            "Epoch 232/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171301.4062 - val_loss: 162491.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 233/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 175118.5781 - val_loss: 162544.8594 - learning_rate: 5.0000e-04\n",
            "Epoch 234/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 185326.5312 - val_loss: 162506.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 235/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176104.4375 - val_loss: 162413.7969 - learning_rate: 5.0000e-04\n",
            "Epoch 236/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 166261.4688 - val_loss: 162511.8125 - learning_rate: 5.0000e-04\n",
            "Epoch 237/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180590.5781 - val_loss: 162625.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 238/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 179889.2656 - val_loss: 162832.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 239/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188138.5625 - val_loss: 162404.5312 - learning_rate: 5.0000e-04\n",
            "Epoch 240/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 185321.6562 - val_loss: 162632.0469 - learning_rate: 5.0000e-04\n",
            "Epoch 241/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176972.6719 - val_loss: 162346.7656 - learning_rate: 5.0000e-04\n",
            "Epoch 242/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181750.2812 - val_loss: 164070.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 243/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 186536.2188 - val_loss: 162437.9844 - learning_rate: 5.0000e-04\n",
            "Epoch 244/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185054.6406 - val_loss: 162399.9219 - learning_rate: 5.0000e-04\n",
            "Epoch 245/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 175976.6562 - val_loss: 162312.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 246/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 194660.2188 - val_loss: 162300.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 247/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 170118.2188 - val_loss: 162473.2969 - learning_rate: 5.0000e-04\n",
            "Epoch 248/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 191210.2656 - val_loss: 162314.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 249/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 165222.5156 - val_loss: 162204.1094 - learning_rate: 5.0000e-04\n",
            "Epoch 250/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179456.9375 - val_loss: 162330.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 251/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 179626.7188 - val_loss: 162246.7188 - learning_rate: 5.0000e-04\n",
            "Epoch 252/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185241.6875 - val_loss: 162118.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 253/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174321.1250 - val_loss: 162131.4062 - learning_rate: 5.0000e-04\n",
            "Epoch 254/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 185369.8125 - val_loss: 161980.8750 - learning_rate: 5.0000e-04\n",
            "Epoch 255/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 175483.9062 - val_loss: 162007.9688 - learning_rate: 5.0000e-04\n",
            "Epoch 256/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 179260.9062 - val_loss: 162418.1875 - learning_rate: 5.0000e-04\n",
            "Epoch 257/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 187701.0000 - val_loss: 162192.2812 - learning_rate: 5.0000e-04\n",
            "Epoch 258/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 168338.2344 - val_loss: 162433.9375 - learning_rate: 5.0000e-04\n",
            "Epoch 259/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 177294.0469 - val_loss: 162142.2500 - learning_rate: 5.0000e-04\n",
            "Epoch 260/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 180802.0938 - val_loss: 162144.5938 - learning_rate: 5.0000e-04\n",
            "Epoch 261/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175109.5312 - val_loss: 162036.1562 - learning_rate: 5.0000e-04\n",
            "Epoch 262/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 166971.8750 - val_loss: 162016.6562 - learning_rate: 5.0000e-04\n",
            "Epoch 263/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178054.7500 - val_loss: 162173.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 264/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 168605.6094 - val_loss: 161992.0156 - learning_rate: 5.0000e-04\n",
            "Epoch 265/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 185284.7969 - val_loss: 161941.9531 - learning_rate: 2.5000e-04\n",
            "Epoch 266/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 169066.2031 - val_loss: 161911.8281 - learning_rate: 2.5000e-04\n",
            "Epoch 267/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 184897.4531 - val_loss: 162098.4688 - learning_rate: 2.5000e-04\n",
            "Epoch 268/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 188080.9375 - val_loss: 162019.6875 - learning_rate: 2.5000e-04\n",
            "Epoch 269/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 192202.2812 - val_loss: 161912.2969 - learning_rate: 2.5000e-04\n",
            "Epoch 270/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173766.1094 - val_loss: 162452.0312 - learning_rate: 2.5000e-04\n",
            "Epoch 271/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 181629.6562 - val_loss: 161940.2344 - learning_rate: 2.5000e-04\n",
            "Epoch 272/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175469.4219 - val_loss: 161811.3125 - learning_rate: 2.5000e-04\n",
            "Epoch 273/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 175949.1250 - val_loss: 161788.7969 - learning_rate: 2.5000e-04\n",
            "Epoch 274/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 188693.8594 - val_loss: 162337.3125 - learning_rate: 2.5000e-04\n",
            "Epoch 275/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173257.0156 - val_loss: 161746.2031 - learning_rate: 2.5000e-04\n",
            "Epoch 276/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176616.2969 - val_loss: 161981.4688 - learning_rate: 2.5000e-04\n",
            "Epoch 277/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 170146.6094 - val_loss: 161714.2969 - learning_rate: 2.5000e-04\n",
            "Epoch 278/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 181549.6250 - val_loss: 161711.0156 - learning_rate: 2.5000e-04\n",
            "Epoch 279/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 199560.1719 - val_loss: 161942.4375 - learning_rate: 2.5000e-04\n",
            "Epoch 280/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 157014.7344 - val_loss: 161701.1094 - learning_rate: 2.5000e-04\n",
            "Epoch 281/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 192733.7188 - val_loss: 161667.4062 - learning_rate: 2.5000e-04\n",
            "Epoch 282/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 165820.2188 - val_loss: 161662.1406 - learning_rate: 2.5000e-04\n",
            "Epoch 283/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 173582.9688 - val_loss: 161715.0312 - learning_rate: 2.5000e-04\n",
            "Epoch 284/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174434.7344 - val_loss: 161659.9219 - learning_rate: 2.5000e-04\n",
            "Epoch 285/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 180409.3594 - val_loss: 161770.6875 - learning_rate: 2.5000e-04\n",
            "Epoch 286/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169824.1094 - val_loss: 161640.7969 - learning_rate: 2.5000e-04\n",
            "Epoch 287/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 170387.3281 - val_loss: 162194.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 288/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 196304.3281 - val_loss: 161752.4531 - learning_rate: 2.5000e-04\n",
            "Epoch 289/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177022.9375 - val_loss: 161567.0312 - learning_rate: 2.5000e-04\n",
            "Epoch 290/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 180343.1250 - val_loss: 161740.7188 - learning_rate: 2.5000e-04\n",
            "Epoch 291/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 197446.3750 - val_loss: 161604.5469 - learning_rate: 2.5000e-04\n",
            "Epoch 292/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 165620.0938 - val_loss: 161544.4844 - learning_rate: 2.5000e-04\n",
            "Epoch 293/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176909.7969 - val_loss: 161860.7812 - learning_rate: 2.5000e-04\n",
            "Epoch 294/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 170971.8750 - val_loss: 161799.2188 - learning_rate: 2.5000e-04\n",
            "Epoch 295/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 192342.1406 - val_loss: 161820.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 296/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 174310.5312 - val_loss: 161915.2344 - learning_rate: 2.5000e-04\n",
            "Epoch 297/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 177936.8281 - val_loss: 161886.2812 - learning_rate: 2.5000e-04\n",
            "Epoch 298/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 166699.3281 - val_loss: 161692.8125 - learning_rate: 2.5000e-04\n",
            "Epoch 299/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173262.5000 - val_loss: 161559.7188 - learning_rate: 2.5000e-04\n",
            "Epoch 300/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 181913.9531 - val_loss: 161527.0938 - learning_rate: 2.5000e-04\n",
            "Epoch 301/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 177434.4062 - val_loss: 161550.6094 - learning_rate: 2.5000e-04\n",
            "Epoch 302/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 175487.7188 - val_loss: 161891.1250 - learning_rate: 2.5000e-04\n",
            "Epoch 303/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 173147.8438 - val_loss: 161520.4375 - learning_rate: 2.5000e-04\n",
            "Epoch 304/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 168943.3281 - val_loss: 161719.8906 - learning_rate: 2.5000e-04\n",
            "Epoch 305/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 184184.0312 - val_loss: 161668.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 306/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 189493.1875 - val_loss: 161659.4375 - learning_rate: 2.5000e-04\n",
            "Epoch 307/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173425.3594 - val_loss: 161409.0312 - learning_rate: 2.5000e-04\n",
            "Epoch 308/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179077.2188 - val_loss: 161417.4375 - learning_rate: 2.5000e-04\n",
            "Epoch 309/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 179961.8281 - val_loss: 161496.9688 - learning_rate: 2.5000e-04\n",
            "Epoch 310/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172707.6250 - val_loss: 161477.6719 - learning_rate: 2.5000e-04\n",
            "Epoch 311/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171953.5000 - val_loss: 161319.6406 - learning_rate: 2.5000e-04\n",
            "Epoch 312/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178646.8750 - val_loss: 161559.1250 - learning_rate: 2.5000e-04\n",
            "Epoch 313/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 167288.8906 - val_loss: 161641.4844 - learning_rate: 2.5000e-04\n",
            "Epoch 314/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 187910.0938 - val_loss: 161529.3750 - learning_rate: 2.5000e-04\n",
            "Epoch 315/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 172990.0312 - val_loss: 161513.5000 - learning_rate: 2.5000e-04\n",
            "Epoch 316/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 185381.9219 - val_loss: 161306.3594 - learning_rate: 2.5000e-04\n",
            "Epoch 317/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171154.0625 - val_loss: 161321.7500 - learning_rate: 2.5000e-04\n",
            "Epoch 318/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 207052.0781 - val_loss: 161550.8438 - learning_rate: 2.5000e-04\n",
            "Epoch 319/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 188617.0625 - val_loss: 161245.2500 - learning_rate: 2.5000e-04\n",
            "Epoch 320/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 193052.6875 - val_loss: 161591.9062 - learning_rate: 2.5000e-04\n",
            "Epoch 321/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176663.1562 - val_loss: 161273.7344 - learning_rate: 2.5000e-04\n",
            "Epoch 322/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172857.9844 - val_loss: 161297.5781 - learning_rate: 2.5000e-04\n",
            "Epoch 323/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 180607.0625 - val_loss: 161285.9219 - learning_rate: 2.5000e-04\n",
            "Epoch 324/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184527.5156 - val_loss: 161273.8594 - learning_rate: 2.5000e-04\n",
            "Epoch 325/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171866.9844 - val_loss: 161403.5469 - learning_rate: 2.5000e-04\n",
            "Epoch 326/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 170273.0469 - val_loss: 161420.2344 - learning_rate: 2.5000e-04\n",
            "Epoch 327/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 174718.6406 - val_loss: 161203.2969 - learning_rate: 2.5000e-04\n",
            "Epoch 328/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178919.7031 - val_loss: 161180.6562 - learning_rate: 2.5000e-04\n",
            "Epoch 329/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184866.0000 - val_loss: 161164.9531 - learning_rate: 2.5000e-04\n",
            "Epoch 330/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179959.8438 - val_loss: 161165.9219 - learning_rate: 2.5000e-04\n",
            "Epoch 331/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 155611.9688 - val_loss: 161153.2188 - learning_rate: 2.5000e-04\n",
            "Epoch 332/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 186737.4375 - val_loss: 161150.1719 - learning_rate: 2.5000e-04\n",
            "Epoch 333/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177012.6719 - val_loss: 161217.8906 - learning_rate: 2.5000e-04\n",
            "Epoch 334/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169987.0312 - val_loss: 161313.0312 - learning_rate: 2.5000e-04\n",
            "Epoch 335/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 202278.0000 - val_loss: 161245.0781 - learning_rate: 2.5000e-04\n",
            "Epoch 336/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180574.4062 - val_loss: 161177.6875 - learning_rate: 2.5000e-04\n",
            "Epoch 337/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184459.9062 - val_loss: 161356.0312 - learning_rate: 2.5000e-04\n",
            "Epoch 338/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180247.4844 - val_loss: 161200.2812 - learning_rate: 2.5000e-04\n",
            "Epoch 339/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175168.5000 - val_loss: 161526.3594 - learning_rate: 2.5000e-04\n",
            "Epoch 340/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 168639.1719 - val_loss: 161260.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 341/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182333.8438 - val_loss: 161254.6250 - learning_rate: 2.5000e-04\n",
            "Epoch 342/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182857.2031 - val_loss: 161172.8281 - learning_rate: 2.5000e-04\n",
            "Epoch 343/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 198553.5000 - val_loss: 161199.9844 - learning_rate: 1.2500e-04\n",
            "Epoch 344/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 181181.1406 - val_loss: 161397.9531 - learning_rate: 1.2500e-04\n",
            "Epoch 345/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 181553.5938 - val_loss: 161356.3750 - learning_rate: 1.2500e-04\n",
            "Epoch 346/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 177472.9844 - val_loss: 161139.7656 - learning_rate: 1.2500e-04\n",
            "Epoch 347/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181482.1094 - val_loss: 161164.7188 - learning_rate: 1.2500e-04\n",
            "Epoch 348/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 188629.9844 - val_loss: 161131.6094 - learning_rate: 1.2500e-04\n",
            "Epoch 349/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 174068.7656 - val_loss: 161251.4844 - learning_rate: 1.2500e-04\n",
            "Epoch 350/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180424.1406 - val_loss: 161271.8594 - learning_rate: 1.2500e-04\n",
            "Epoch 351/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 196654.4844 - val_loss: 161298.1250 - learning_rate: 1.2500e-04\n",
            "Epoch 352/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169838.1562 - val_loss: 161444.6562 - learning_rate: 1.2500e-04\n",
            "Epoch 353/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177458.2188 - val_loss: 161192.6719 - learning_rate: 1.2500e-04\n",
            "Epoch 354/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168574.4531 - val_loss: 161249.1719 - learning_rate: 1.2500e-04\n",
            "Epoch 355/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 185727.6562 - val_loss: 161091.5781 - learning_rate: 1.2500e-04\n",
            "Epoch 356/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 207154.2656 - val_loss: 161521.7344 - learning_rate: 1.2500e-04\n",
            "Epoch 357/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 177156.4062 - val_loss: 161222.8750 - learning_rate: 1.2500e-04\n",
            "Epoch 358/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 181991.6875 - val_loss: 161125.3438 - learning_rate: 1.2500e-04\n",
            "Epoch 359/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179362.1406 - val_loss: 161138.7969 - learning_rate: 1.2500e-04\n",
            "Epoch 360/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 175641.9375 - val_loss: 161080.1719 - learning_rate: 1.2500e-04\n",
            "Epoch 361/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188500.7656 - val_loss: 161289.2812 - learning_rate: 1.2500e-04\n",
            "Epoch 362/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 193426.8594 - val_loss: 161189.7344 - learning_rate: 1.2500e-04\n",
            "Epoch 363/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 185664.8750 - val_loss: 161137.4844 - learning_rate: 1.2500e-04\n",
            "Epoch 364/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 178577.2656 - val_loss: 161376.4844 - learning_rate: 1.2500e-04\n",
            "Epoch 365/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173128.8438 - val_loss: 161158.8750 - learning_rate: 1.2500e-04\n",
            "Epoch 366/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 178251.7031 - val_loss: 161117.3438 - learning_rate: 1.2500e-04\n",
            "Epoch 367/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181958.2812 - val_loss: 161135.2812 - learning_rate: 1.2500e-04\n",
            "Epoch 368/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169657.8281 - val_loss: 161231.9531 - learning_rate: 1.2500e-04\n",
            "Epoch 369/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 154366.5625 - val_loss: 161432.7500 - learning_rate: 1.2500e-04\n",
            "Epoch 370/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 187762.3438 - val_loss: 161385.8750 - learning_rate: 1.2500e-04\n",
            "Epoch 371/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 186549.2812 - val_loss: 161147.0312 - learning_rate: 6.2500e-05\n",
            "Epoch 372/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 181821.2500 - val_loss: 161083.3438 - learning_rate: 6.2500e-05\n",
            "Epoch 373/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 163098.1875 - val_loss: 161174.5156 - learning_rate: 6.2500e-05\n",
            "Epoch 374/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 195077.4844 - val_loss: 161050.4375 - learning_rate: 6.2500e-05\n",
            "Epoch 375/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 158046.8750 - val_loss: 161189.1406 - learning_rate: 6.2500e-05\n",
            "Epoch 376/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172061.7812 - val_loss: 161147.0781 - learning_rate: 6.2500e-05\n",
            "Epoch 377/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 176971.7812 - val_loss: 161226.3281 - learning_rate: 6.2500e-05\n",
            "Epoch 378/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 175897.4844 - val_loss: 161166.7812 - learning_rate: 6.2500e-05\n",
            "Epoch 379/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188304.8125 - val_loss: 161130.6250 - learning_rate: 6.2500e-05\n",
            "Epoch 380/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 187404.6719 - val_loss: 161043.1250 - learning_rate: 6.2500e-05\n",
            "Epoch 381/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 182947.1719 - val_loss: 161061.6875 - learning_rate: 6.2500e-05\n",
            "Epoch 382/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168860.4375 - val_loss: 161177.2812 - learning_rate: 6.2500e-05\n",
            "Epoch 383/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 169659.1094 - val_loss: 161239.7656 - learning_rate: 6.2500e-05\n",
            "Epoch 384/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169706.3125 - val_loss: 161171.5938 - learning_rate: 6.2500e-05\n",
            "Epoch 385/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 161233.1406 - val_loss: 161313.5000 - learning_rate: 6.2500e-05\n",
            "Epoch 386/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 188804.8906 - val_loss: 161295.5000 - learning_rate: 6.2500e-05\n",
            "Epoch 387/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 165997.2500 - val_loss: 161181.6406 - learning_rate: 6.2500e-05\n",
            "Epoch 388/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 172165.5938 - val_loss: 161104.9062 - learning_rate: 6.2500e-05\n",
            "Epoch 389/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 178657.6406 - val_loss: 161020.4688 - learning_rate: 6.2500e-05\n",
            "Epoch 390/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 189714.8438 - val_loss: 160985.1250 - learning_rate: 6.2500e-05\n",
            "Epoch 391/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 170160.0781 - val_loss: 160992.2344 - learning_rate: 6.2500e-05\n",
            "Epoch 392/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 212368.1250 - val_loss: 161000.2812 - learning_rate: 6.2500e-05\n",
            "Epoch 393/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 179827.7188 - val_loss: 161011.3281 - learning_rate: 6.2500e-05\n",
            "Epoch 394/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 182123.0156 - val_loss: 160982.3281 - learning_rate: 6.2500e-05\n",
            "Epoch 395/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171139.6562 - val_loss: 161061.3750 - learning_rate: 6.2500e-05\n",
            "Epoch 396/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 168169.1875 - val_loss: 161006.9375 - learning_rate: 6.2500e-05\n",
            "Epoch 397/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 178086.5000 - val_loss: 160996.6094 - learning_rate: 6.2500e-05\n",
            "Epoch 398/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 183135.0156 - val_loss: 160986.2969 - learning_rate: 6.2500e-05\n",
            "Epoch 399/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 167694.0938 - val_loss: 160969.5000 - learning_rate: 6.2500e-05\n",
            "Epoch 400/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 187978.2656 - val_loss: 161055.0781 - learning_rate: 6.2500e-05\n",
            "Epoch 401/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 174222.0625 - val_loss: 160998.4531 - learning_rate: 6.2500e-05\n",
            "Epoch 402/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 181987.2500 - val_loss: 160978.5938 - learning_rate: 6.2500e-05\n",
            "Epoch 403/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 193144.2344 - val_loss: 161004.0781 - learning_rate: 6.2500e-05\n",
            "Epoch 404/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 166580.0781 - val_loss: 160985.5781 - learning_rate: 6.2500e-05\n",
            "Epoch 405/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173110.4062 - val_loss: 160963.8750 - learning_rate: 6.2500e-05\n",
            "Epoch 406/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 175601.4531 - val_loss: 160954.0156 - learning_rate: 6.2500e-05\n",
            "Epoch 407/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 191847.2500 - val_loss: 161043.3750 - learning_rate: 6.2500e-05\n",
            "Epoch 408/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 172854.0156 - val_loss: 161055.0469 - learning_rate: 6.2500e-05\n",
            "Epoch 409/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176964.5000 - val_loss: 161015.5469 - learning_rate: 6.2500e-05\n",
            "Epoch 410/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 179303.2656 - val_loss: 160952.2344 - learning_rate: 6.2500e-05\n",
            "Epoch 411/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 172806.5781 - val_loss: 160946.3594 - learning_rate: 6.2500e-05\n",
            "Epoch 412/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180565.7031 - val_loss: 160937.9219 - learning_rate: 6.2500e-05\n",
            "Epoch 413/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 183383.3750 - val_loss: 160945.8438 - learning_rate: 6.2500e-05\n",
            "Epoch 414/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176725.7500 - val_loss: 160957.5156 - learning_rate: 6.2500e-05\n",
            "Epoch 415/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178930.5000 - val_loss: 160983.9688 - learning_rate: 6.2500e-05\n",
            "Epoch 416/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 172524.3438 - val_loss: 160990.1406 - learning_rate: 6.2500e-05\n",
            "Epoch 417/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176885.0781 - val_loss: 160967.9688 - learning_rate: 6.2500e-05\n",
            "Epoch 418/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 171104.2656 - val_loss: 160992.9844 - learning_rate: 6.2500e-05\n",
            "Epoch 419/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179443.5156 - val_loss: 160997.5469 - learning_rate: 6.2500e-05\n",
            "Epoch 420/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176852.8125 - val_loss: 161017.3750 - learning_rate: 6.2500e-05\n",
            "Epoch 421/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 179958.5781 - val_loss: 160965.4219 - learning_rate: 6.2500e-05\n",
            "Epoch 422/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 192147.5781 - val_loss: 160949.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 423/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 162630.6562 - val_loss: 160947.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 424/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 170185.6562 - val_loss: 160951.7656 - learning_rate: 3.1250e-05\n",
            "Epoch 425/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180617.7500 - val_loss: 160955.2188 - learning_rate: 3.1250e-05\n",
            "Epoch 426/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 179993.1094 - val_loss: 160946.0156 - learning_rate: 3.1250e-05\n",
            "Epoch 427/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 189737.1719 - val_loss: 160933.4844 - learning_rate: 3.1250e-05\n",
            "Epoch 428/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 162971.9219 - val_loss: 160937.4219 - learning_rate: 3.1250e-05\n",
            "Epoch 429/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 171898.1406 - val_loss: 160944.2031 - learning_rate: 3.1250e-05\n",
            "Epoch 430/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 166053.8438 - val_loss: 160936.0625 - learning_rate: 3.1250e-05\n",
            "Epoch 431/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 180722.6719 - val_loss: 160928.6094 - learning_rate: 3.1250e-05\n",
            "Epoch 432/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 165485.0938 - val_loss: 160930.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 433/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178824.2188 - val_loss: 160925.7812 - learning_rate: 3.1250e-05\n",
            "Epoch 434/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 193277.1562 - val_loss: 160929.1562 - learning_rate: 3.1250e-05\n",
            "Epoch 435/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169432.4219 - val_loss: 160925.2344 - learning_rate: 3.1250e-05\n",
            "Epoch 436/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168710.2031 - val_loss: 160929.7812 - learning_rate: 3.1250e-05\n",
            "Epoch 437/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 189471.2188 - val_loss: 160930.3281 - learning_rate: 3.1250e-05\n",
            "Epoch 438/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 168379.0156 - val_loss: 160920.2344 - learning_rate: 3.1250e-05\n",
            "Epoch 439/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178989.2656 - val_loss: 160926.5000 - learning_rate: 3.1250e-05\n",
            "Epoch 440/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174160.9062 - val_loss: 160951.1875 - learning_rate: 3.1250e-05\n",
            "Epoch 441/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 191307.7812 - val_loss: 160927.0938 - learning_rate: 3.1250e-05\n",
            "Epoch 442/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 184919.3750 - val_loss: 160925.5312 - learning_rate: 3.1250e-05\n",
            "Epoch 443/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 186871.4531 - val_loss: 160912.3438 - learning_rate: 3.1250e-05\n",
            "Epoch 444/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169898.5312 - val_loss: 160913.5781 - learning_rate: 3.1250e-05\n",
            "Epoch 445/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177552.3438 - val_loss: 160921.2344 - learning_rate: 3.1250e-05\n",
            "Epoch 446/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 192557.6250 - val_loss: 160919.1250 - learning_rate: 3.1250e-05\n",
            "Epoch 447/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 185782.1562 - val_loss: 160956.6250 - learning_rate: 3.1250e-05\n",
            "Epoch 448/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180451.4844 - val_loss: 160979.4375 - learning_rate: 3.1250e-05\n",
            "Epoch 449/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 186274.0938 - val_loss: 160950.6719 - learning_rate: 3.1250e-05\n",
            "Epoch 450/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176783.0312 - val_loss: 160935.4688 - learning_rate: 3.1250e-05\n",
            "Epoch 451/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169114.3281 - val_loss: 160922.4062 - learning_rate: 3.1250e-05\n",
            "Epoch 452/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176419.6719 - val_loss: 160911.5312 - learning_rate: 3.1250e-05\n",
            "Epoch 453/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 174094.5469 - val_loss: 160939.7031 - learning_rate: 3.1250e-05\n",
            "Epoch 454/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 174353.5938 - val_loss: 160928.5000 - learning_rate: 3.1250e-05\n",
            "Epoch 455/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180564.6562 - val_loss: 160907.8281 - learning_rate: 3.1250e-05\n",
            "Epoch 456/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 180947.0156 - val_loss: 160910.8750 - learning_rate: 3.1250e-05\n",
            "Epoch 457/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169106.0000 - val_loss: 160911.6719 - learning_rate: 3.1250e-05\n",
            "Epoch 458/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 176452.5312 - val_loss: 160911.7031 - learning_rate: 3.1250e-05\n",
            "Epoch 459/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176256.2344 - val_loss: 160925.3750 - learning_rate: 3.1250e-05\n",
            "Epoch 460/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176926.1094 - val_loss: 160910.4531 - learning_rate: 3.1250e-05\n",
            "Epoch 461/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 163415.1562 - val_loss: 160897.3750 - learning_rate: 3.1250e-05\n",
            "Epoch 462/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 176402.3906 - val_loss: 160985.8906 - learning_rate: 3.1250e-05\n",
            "Epoch 463/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 180203.6250 - val_loss: 161002.0469 - learning_rate: 3.1250e-05\n",
            "Epoch 464/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 178814.5469 - val_loss: 160981.7656 - learning_rate: 3.1250e-05\n",
            "Epoch 465/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 167663.7500 - val_loss: 160946.7500 - learning_rate: 3.1250e-05\n",
            "Epoch 466/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 164400.0312 - val_loss: 160980.2344 - learning_rate: 3.1250e-05\n",
            "Epoch 467/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 172674.5781 - val_loss: 160951.7031 - learning_rate: 3.1250e-05\n",
            "Epoch 468/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169629.4062 - val_loss: 160917.1406 - learning_rate: 3.1250e-05\n",
            "Epoch 469/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173779.6562 - val_loss: 160996.6250 - learning_rate: 3.1250e-05\n",
            "Epoch 470/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 179802.4375 - val_loss: 160989.0312 - learning_rate: 3.1250e-05\n",
            "Epoch 471/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 167571.5000 - val_loss: 160909.6094 - learning_rate: 3.1250e-05\n",
            "Epoch 472/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 173408.1719 - val_loss: 160910.3750 - learning_rate: 1.5625e-05\n",
            "Epoch 473/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 174640.5000 - val_loss: 160888.2344 - learning_rate: 1.5625e-05\n",
            "Epoch 474/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 178375.2969 - val_loss: 160889.2656 - learning_rate: 1.5625e-05\n",
            "Epoch 475/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 167037.1250 - val_loss: 160884.9844 - learning_rate: 1.5625e-05\n",
            "Epoch 476/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 183211.2656 - val_loss: 160884.5938 - learning_rate: 1.5625e-05\n",
            "Epoch 477/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169297.7500 - val_loss: 160880.7656 - learning_rate: 1.5625e-05\n",
            "Epoch 478/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177201.1875 - val_loss: 160880.4688 - learning_rate: 1.5625e-05\n",
            "Epoch 479/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 178825.0781 - val_loss: 160879.3750 - learning_rate: 1.5625e-05\n",
            "Epoch 480/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 180805.3281 - val_loss: 160877.6875 - learning_rate: 1.5625e-05\n",
            "Epoch 481/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181044.7656 - val_loss: 160901.0469 - learning_rate: 1.5625e-05\n",
            "Epoch 482/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180098.9375 - val_loss: 160879.2812 - learning_rate: 1.5625e-05\n",
            "Epoch 483/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 204987.4688 - val_loss: 160872.8750 - learning_rate: 1.5625e-05\n",
            "Epoch 484/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 190010.5781 - val_loss: 160872.4062 - learning_rate: 1.5625e-05\n",
            "Epoch 485/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 178283.8906 - val_loss: 160872.3906 - learning_rate: 1.5625e-05\n",
            "Epoch 486/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169709.3125 - val_loss: 160880.5000 - learning_rate: 1.5625e-05\n",
            "Epoch 487/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 183052.9375 - val_loss: 160883.9531 - learning_rate: 1.5625e-05\n",
            "Epoch 488/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 179339.4844 - val_loss: 160882.3594 - learning_rate: 1.5625e-05\n",
            "Epoch 489/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 181083.9844 - val_loss: 160885.5781 - learning_rate: 1.5625e-05\n",
            "Epoch 490/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 195387.2812 - val_loss: 160879.5156 - learning_rate: 1.5625e-05\n",
            "Epoch 491/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177632.4375 - val_loss: 160878.9375 - learning_rate: 1.5625e-05\n",
            "Epoch 492/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 175984.9844 - val_loss: 160877.5781 - learning_rate: 1.5625e-05\n",
            "Epoch 493/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 173781.2500 - val_loss: 160888.1719 - learning_rate: 1.5625e-05\n",
            "Epoch 494/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 202631.8906 - val_loss: 160871.7656 - learning_rate: 1.5625e-05\n",
            "Epoch 495/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 153764.1250 - val_loss: 160873.2188 - learning_rate: 1.5625e-05\n",
            "Epoch 496/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 173855.7656 - val_loss: 160871.1562 - learning_rate: 1.5625e-05\n",
            "Epoch 497/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171642.2969 - val_loss: 160870.6562 - learning_rate: 1.5625e-05\n",
            "Epoch 498/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 189875.7656 - val_loss: 160873.2656 - learning_rate: 1.5625e-05\n",
            "Epoch 499/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 190008.2500 - val_loss: 160878.8906 - learning_rate: 1.5625e-05\n",
            "Epoch 500/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 171761.8125 - val_loss: 160882.0156 - learning_rate: 1.5625e-05\n",
            "Epoch 501/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 169610.4219 - val_loss: 160877.8594 - learning_rate: 1.5625e-05\n",
            "Epoch 502/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 182491.4375 - val_loss: 160866.3594 - learning_rate: 1.5625e-05\n",
            "Epoch 503/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 186864.4062 - val_loss: 160863.1875 - learning_rate: 1.5625e-05\n",
            "Epoch 504/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182721.1562 - val_loss: 160858.5938 - learning_rate: 1.5625e-05\n",
            "Epoch 505/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173679.5000 - val_loss: 160857.4375 - learning_rate: 1.5625e-05\n",
            "Epoch 506/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 180159.9375 - val_loss: 160858.3281 - learning_rate: 1.5625e-05\n",
            "Epoch 507/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 181221.0625 - val_loss: 160855.5000 - learning_rate: 1.5625e-05\n",
            "Epoch 508/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 170032.5781 - val_loss: 160856.6562 - learning_rate: 1.5625e-05\n",
            "Epoch 509/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 171322.6562 - val_loss: 160865.7031 - learning_rate: 1.5625e-05\n",
            "Epoch 510/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 177679.7812 - val_loss: 160868.0781 - learning_rate: 1.5625e-05\n",
            "Epoch 511/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 181515.4375 - val_loss: 160869.2500 - learning_rate: 1.5625e-05\n",
            "Epoch 512/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 170924.4688 - val_loss: 160869.2500 - learning_rate: 1.5625e-05\n",
            "Epoch 513/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 183046.2188 - val_loss: 160870.9062 - learning_rate: 1.5625e-05\n",
            "Epoch 514/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 164765.8125 - val_loss: 160869.0469 - learning_rate: 1.5625e-05\n",
            "Epoch 515/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 176846.8594 - val_loss: 160888.3906 - learning_rate: 1.5625e-05\n",
            "Epoch 516/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 196675.8750 - val_loss: 160883.7969 - learning_rate: 1.5625e-05\n",
            "Epoch 517/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 166532.6406 - val_loss: 160862.1875 - learning_rate: 1.5625e-05\n",
            "Epoch 518/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 163231.3125 - val_loss: 160867.2656 - learning_rate: 7.8125e-06\n",
            "Epoch 519/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 172549.8281 - val_loss: 160870.7500 - learning_rate: 7.8125e-06\n",
            "Epoch 520/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 172505.7344 - val_loss: 160873.5156 - learning_rate: 7.8125e-06\n",
            "Epoch 521/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 183388.7188 - val_loss: 160872.4844 - learning_rate: 7.8125e-06\n",
            "Epoch 522/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 184111.0312 - val_loss: 160885.1875 - learning_rate: 7.8125e-06\n",
            "Epoch 523/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 179646.6406 - val_loss: 160888.5156 - learning_rate: 7.8125e-06\n",
            "Epoch 524/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 182306.1094 - val_loss: 160887.2188 - learning_rate: 7.8125e-06\n",
            "Epoch 525/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 183657.3594 - val_loss: 160869.1250 - learning_rate: 7.8125e-06\n",
            "Epoch 526/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 173610.7656 - val_loss: 160859.4375 - learning_rate: 7.8125e-06\n",
            "Epoch 527/1000\n",
            "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 162993.4688 - val_loss: 160856.0469 - learning_rate: 7.8125e-06\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 201996.1562 \n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "R Squared: 0.38685041666030884\n",
            "Mean Absolute Error: 342.7507019042969\n",
            "Mean Squared Error: 190982.34375\n",
            "Root Mean Squared Error: 437.0152671818228\n",
            "Scatter Index: 0.5219864270072176\n"
          ]
        }
      ]
    }
  ]
}